{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasResNetfreeze.ipynb",
      "provenance": [],
      "mount_file_id": "1psvg0lqb6ocUT8RSDqPQSSQH8WJ_PJxw",
      "authorship_tag": "ABX9TyPoQ47qeKmCAAXNjfa9gMm6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/watcharakiete/TOC-Assignment/blob/master/kerasResNetfreeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cXaxm2wAmX6x",
        "outputId": "b84e94dd-a0ba-42b9-ee83-225849ac4d7f"
      },
      "source": [
        "#!/usr/bin/env python3\r\n",
        "\"\"\"\r\n",
        "Trains a convolutional neural network to classify the CIFAR 10 dataset:\r\n",
        "\"\"\"\r\n",
        "%tensorflow_version 1.x\r\n",
        "import tensorflow.keras as K\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "\r\n",
        "def preprocess_data(X, Y):\r\n",
        "    \"\"\"\r\n",
        "    a function that trains a convolutional neural network to classify the\r\n",
        "    CIFAR 10 dataset\r\n",
        "    :param X: X is a numpy.ndarray of shape (m, 32, 32, 3) containing the\r\n",
        "    CIFAR 10 data, where m is the number of data points\r\n",
        "    :param Y: Y is a numpy.ndarray of shape (m,) containing the CIFAR 10\r\n",
        "    labels for X\r\n",
        "    :return: X_p, Y_p\r\n",
        "        X_p is a numpy.ndarray containing the preprocessed X\r\n",
        "        Y_p is a numpy.ndarray containing the preprocessed Y\r\n",
        "    \"\"\"\r\n",
        "    X_p = K.applications.resnet50.preprocess_input(X)\r\n",
        "    Y_p = K.utils.to_categorical(Y, 1)\r\n",
        "    return X_p, Y_p\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    #(x_train, y_train), (x_test, y_test) = K.datasets.cifar10.load_data()\r\n",
        "    (x_train, y_train), (x_test, y_test) = K.datasets.cifar10.load_data()\r\n",
        "    print((x_train.shape, y_train.shape))\r\n",
        "    x_train, y_train = preprocess_data(x_train, y_train)\r\n",
        "    x_test, y_test = preprocess_data(x_test, y_test)\r\n",
        "    print((x_train.shape, y_train.shape))\r\n",
        "\r\n",
        "    input_t = K.Input(shape=(32, 32, 3))\r\n",
        "    res_model = K.applications.ResNet50(include_top=False,\r\n",
        "                                        weights=\"imagenet\",\r\n",
        "                                        input_tensor=input_t)\r\n",
        "    \r\n",
        "    \r\n",
        "    for layer in res_model.layers[:143]:\r\n",
        "        layer.trainable = False\r\n",
        "\r\n",
        "    for i, layer in enumerate(res_model.layers):\r\n",
        "        print(i, layer.name, \"-\", layer.trainable)\r\n",
        "\r\n",
        "    to_res = (224, 224)\r\n",
        "    model = K.models.Sequential()\r\n",
        "    #model.add(K.layers.Lambda(lambda image: tf.image.resize(image, to_res))) \r\n",
        "    model.add(res_model)\r\n",
        "    model.add(K.layers.Flatten())\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(256, activation='relu'))\r\n",
        "    model.add(K.layers.Dropout(0.5))\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(128, activation='relu'))\r\n",
        "    model.add(K.layers.Dropout(0.5))\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(64, activation='relu'))\r\n",
        "    model.add(K.layers.Dropout(0.5))\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(1, activation='softmax'))\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "    check_point = K.callbacks.ModelCheckpoint(filepath=\"test.h5\",\r\n",
        "                                              monitor=\"val_acc\",\r\n",
        "                                              mode=\"max\",\r\n",
        "                                              save_best_only=True,\r\n",
        "                                              )\r\n",
        "\r\n",
        "    model.compile(loss='categorical_crossentropy',\r\n",
        "                  optimizer=K.optimizers.RMSprop(lr=2e-5),\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    history = model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=1,\r\n",
        "                        validation_data=(x_test, y_test),\r\n",
        "                        callbacks=[check_point])\r\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((50000, 32, 32, 3), (50000, 1))\n",
            "((50000, 32, 32, 3), (50000, 10))\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 3s 0us/step\n",
            "0 input_2 - False\n",
            "1 conv1_pad - False\n",
            "2 conv1_conv - False\n",
            "3 conv1_bn - False\n",
            "4 conv1_relu - False\n",
            "5 pool1_pad - False\n",
            "6 pool1_pool - False\n",
            "7 conv2_block1_1_conv - False\n",
            "8 conv2_block1_1_bn - False\n",
            "9 conv2_block1_1_relu - False\n",
            "10 conv2_block1_2_conv - False\n",
            "11 conv2_block1_2_bn - False\n",
            "12 conv2_block1_2_relu - False\n",
            "13 conv2_block1_0_conv - False\n",
            "14 conv2_block1_3_conv - False\n",
            "15 conv2_block1_0_bn - False\n",
            "16 conv2_block1_3_bn - False\n",
            "17 conv2_block1_add - False\n",
            "18 conv2_block1_out - False\n",
            "19 conv2_block2_1_conv - False\n",
            "20 conv2_block2_1_bn - False\n",
            "21 conv2_block2_1_relu - False\n",
            "22 conv2_block2_2_conv - False\n",
            "23 conv2_block2_2_bn - False\n",
            "24 conv2_block2_2_relu - False\n",
            "25 conv2_block2_3_conv - False\n",
            "26 conv2_block2_3_bn - False\n",
            "27 conv2_block2_add - False\n",
            "28 conv2_block2_out - False\n",
            "29 conv2_block3_1_conv - False\n",
            "30 conv2_block3_1_bn - False\n",
            "31 conv2_block3_1_relu - False\n",
            "32 conv2_block3_2_conv - False\n",
            "33 conv2_block3_2_bn - False\n",
            "34 conv2_block3_2_relu - False\n",
            "35 conv2_block3_3_conv - False\n",
            "36 conv2_block3_3_bn - False\n",
            "37 conv2_block3_add - False\n",
            "38 conv2_block3_out - False\n",
            "39 conv3_block1_1_conv - False\n",
            "40 conv3_block1_1_bn - False\n",
            "41 conv3_block1_1_relu - False\n",
            "42 conv3_block1_2_conv - False\n",
            "43 conv3_block1_2_bn - False\n",
            "44 conv3_block1_2_relu - False\n",
            "45 conv3_block1_0_conv - False\n",
            "46 conv3_block1_3_conv - False\n",
            "47 conv3_block1_0_bn - False\n",
            "48 conv3_block1_3_bn - False\n",
            "49 conv3_block1_add - False\n",
            "50 conv3_block1_out - False\n",
            "51 conv3_block2_1_conv - False\n",
            "52 conv3_block2_1_bn - False\n",
            "53 conv3_block2_1_relu - False\n",
            "54 conv3_block2_2_conv - False\n",
            "55 conv3_block2_2_bn - False\n",
            "56 conv3_block2_2_relu - False\n",
            "57 conv3_block2_3_conv - False\n",
            "58 conv3_block2_3_bn - False\n",
            "59 conv3_block2_add - False\n",
            "60 conv3_block2_out - False\n",
            "61 conv3_block3_1_conv - False\n",
            "62 conv3_block3_1_bn - False\n",
            "63 conv3_block3_1_relu - False\n",
            "64 conv3_block3_2_conv - False\n",
            "65 conv3_block3_2_bn - False\n",
            "66 conv3_block3_2_relu - False\n",
            "67 conv3_block3_3_conv - False\n",
            "68 conv3_block3_3_bn - False\n",
            "69 conv3_block3_add - False\n",
            "70 conv3_block3_out - False\n",
            "71 conv3_block4_1_conv - False\n",
            "72 conv3_block4_1_bn - False\n",
            "73 conv3_block4_1_relu - False\n",
            "74 conv3_block4_2_conv - False\n",
            "75 conv3_block4_2_bn - False\n",
            "76 conv3_block4_2_relu - False\n",
            "77 conv3_block4_3_conv - False\n",
            "78 conv3_block4_3_bn - False\n",
            "79 conv3_block4_add - False\n",
            "80 conv3_block4_out - False\n",
            "81 conv4_block1_1_conv - False\n",
            "82 conv4_block1_1_bn - False\n",
            "83 conv4_block1_1_relu - False\n",
            "84 conv4_block1_2_conv - False\n",
            "85 conv4_block1_2_bn - False\n",
            "86 conv4_block1_2_relu - False\n",
            "87 conv4_block1_0_conv - False\n",
            "88 conv4_block1_3_conv - False\n",
            "89 conv4_block1_0_bn - False\n",
            "90 conv4_block1_3_bn - False\n",
            "91 conv4_block1_add - False\n",
            "92 conv4_block1_out - False\n",
            "93 conv4_block2_1_conv - False\n",
            "94 conv4_block2_1_bn - False\n",
            "95 conv4_block2_1_relu - False\n",
            "96 conv4_block2_2_conv - False\n",
            "97 conv4_block2_2_bn - False\n",
            "98 conv4_block2_2_relu - False\n",
            "99 conv4_block2_3_conv - False\n",
            "100 conv4_block2_3_bn - False\n",
            "101 conv4_block2_add - False\n",
            "102 conv4_block2_out - False\n",
            "103 conv4_block3_1_conv - False\n",
            "104 conv4_block3_1_bn - False\n",
            "105 conv4_block3_1_relu - False\n",
            "106 conv4_block3_2_conv - False\n",
            "107 conv4_block3_2_bn - False\n",
            "108 conv4_block3_2_relu - False\n",
            "109 conv4_block3_3_conv - False\n",
            "110 conv4_block3_3_bn - False\n",
            "111 conv4_block3_add - False\n",
            "112 conv4_block3_out - False\n",
            "113 conv4_block4_1_conv - False\n",
            "114 conv4_block4_1_bn - False\n",
            "115 conv4_block4_1_relu - False\n",
            "116 conv4_block4_2_conv - False\n",
            "117 conv4_block4_2_bn - False\n",
            "118 conv4_block4_2_relu - False\n",
            "119 conv4_block4_3_conv - False\n",
            "120 conv4_block4_3_bn - False\n",
            "121 conv4_block4_add - False\n",
            "122 conv4_block4_out - False\n",
            "123 conv4_block5_1_conv - False\n",
            "124 conv4_block5_1_bn - False\n",
            "125 conv4_block5_1_relu - False\n",
            "126 conv4_block5_2_conv - False\n",
            "127 conv4_block5_2_bn - False\n",
            "128 conv4_block5_2_relu - False\n",
            "129 conv4_block5_3_conv - False\n",
            "130 conv4_block5_3_bn - False\n",
            "131 conv4_block5_add - False\n",
            "132 conv4_block5_out - False\n",
            "133 conv4_block6_1_conv - False\n",
            "134 conv4_block6_1_bn - False\n",
            "135 conv4_block6_1_relu - False\n",
            "136 conv4_block6_2_conv - False\n",
            "137 conv4_block6_2_bn - False\n",
            "138 conv4_block6_2_relu - False\n",
            "139 conv4_block6_3_conv - False\n",
            "140 conv4_block6_3_bn - False\n",
            "141 conv4_block6_add - False\n",
            "142 conv4_block6_out - False\n",
            "143 conv5_block1_1_conv - True\n",
            "144 conv5_block1_1_bn - True\n",
            "145 conv5_block1_1_relu - True\n",
            "146 conv5_block1_2_conv - True\n",
            "147 conv5_block1_2_bn - True\n",
            "148 conv5_block1_2_relu - True\n",
            "149 conv5_block1_0_conv - True\n",
            "150 conv5_block1_3_conv - True\n",
            "151 conv5_block1_0_bn - True\n",
            "152 conv5_block1_3_bn - True\n",
            "153 conv5_block1_add - True\n",
            "154 conv5_block1_out - True\n",
            "155 conv5_block2_1_conv - True\n",
            "156 conv5_block2_1_bn - True\n",
            "157 conv5_block2_1_relu - True\n",
            "158 conv5_block2_2_conv - True\n",
            "159 conv5_block2_2_bn - True\n",
            "160 conv5_block2_2_relu - True\n",
            "161 conv5_block2_3_conv - True\n",
            "162 conv5_block2_3_bn - True\n",
            "163 conv5_block2_add - True\n",
            "164 conv5_block2_out - True\n",
            "165 conv5_block3_1_conv - True\n",
            "166 conv5_block3_1_bn - True\n",
            "167 conv5_block3_1_relu - True\n",
            "168 conv5_block3_2_conv - True\n",
            "169 conv5_block3_2_bn - True\n",
            "170 conv5_block3_2_relu - True\n",
            "171 conv5_block3_3_conv - True\n",
            "172 conv5_block3_3_bn - True\n",
            "173 conv5_block3_add - True\n",
            "174 conv5_block3_out - True\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "30944/50000 [=================>............] - ETA: 1:58:44 - loss: 2.2090 - acc: 0.2638"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-811c5804af23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     history = model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1,\n\u001b[1;32m     75\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                         callbacks=[check_point])\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# model.save(\"cifar10.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYBdqABJmbaY"
      },
      "source": [
        "# preprocess_data = __import__('0-transfer').preprocess_data\r\n",
        "\r\n",
        "# fix issue with saving keras applications\r\n",
        "K.learning_phase = K.backend.learning_phase\r\n",
        "\r\n",
        "_, (X, Y) = K.datasets.cifar10.load_data()\r\n",
        "X_p, Y_p = preprocess_data(X, Y)\r\n",
        "model = K.models.load_model('cifar10.h5')\r\n",
        "model.evaluate(X_p, Y_p, batch_size=128, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9WIPgLAmgea"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\r\n",
        "plt.plot(epochs, val_acc, 'bo', label='Validation acc')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'ro', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3W2dXGfdCHy"
      },
      "source": [
        "# Test ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phS-r-zdmuzB",
        "outputId": "cc716cc1-9e2c-4c33-d4da-bd84b3bfe023"
      },
      "source": [
        "#!/usr/bin/env python3\r\n",
        "\"\"\"\r\n",
        "Trains a convolutional neural network to classify the CIFAR 10 dataset:\r\n",
        "\"\"\"\r\n",
        "%tensorflow_version 1.x\r\n",
        "import tensorflow.keras as K\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  \r\n",
        "    \"\"\"\r\n",
        "    #(x_train, y_train), (x_test, y_test) = K.datasets.cifar10.load_data()\r\n",
        "    (x_train, y_train), (x_test, y_test) = K.datasets.cifar10.load_data()\r\n",
        "    print((x_train.shape, y_train.shape))\r\n",
        "    x_train, y_train = preprocess_data(x_train, y_train)\r\n",
        "    x_test, y_test = preprocess_data(x_test, y_test)\r\n",
        "    print((x_train.shape, y_train.shape))\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "\r\n",
        "    input_t = K.Input(shape=(32, 32, 3))\r\n",
        "    res_model = K.applications.ResNet50(include_top=False,\r\n",
        "                                        weights=\"imagenet\",\r\n",
        "                                        input_tensor=input_t)\r\n",
        "    \r\n",
        "    for layer in res_model.layers[:143]:\r\n",
        "        layer.trainable = False\r\n",
        "\r\n",
        "    for i, layer in enumerate(res_model.layers):\r\n",
        "        print(i, layer.name, \"-\", layer.trainable)\r\n",
        "\r\n",
        "    to_res = (224, 224)\r\n",
        "    model = K.models.Sequential()\r\n",
        "    #model.add(K.layers.Lambda(lambda image: tf.image.resize(image, to_res))) \r\n",
        "    model.add(res_model)\r\n",
        "    \"\"\"\r\n",
        "    model.add(K.layers.Flatten())\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(256, activation='relu'))\r\n",
        "    model.add(K.layers.Dropout(0.5))\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(128, activation='relu'))\r\n",
        "    model.add(K.layers.Dropout(0.5))\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(64, activation='relu'))\r\n",
        "    model.add(K.layers.Dropout(0.5))\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(1, activation='softmax'))\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    model.add(K.layers.Flatten())\r\n",
        "    model.add(K.layers.BatchNormalization())\r\n",
        "    model.add(K.layers.Dense(2048, activation='relu'))\r\n",
        "    model.add(K.layers.Dropout(0.5))\r\n",
        "\r\n",
        "    model.add(K.layers.Dense(11*11*(1+2*5), activation='relu'))\r\n",
        "\r\n",
        "    check_point = K.callbacks.ModelCheckpoint(filepath=\"test.h5\",\r\n",
        "                                              monitor=\"val_acc\",\r\n",
        "                                              mode=\"max\",\r\n",
        "                                              save_best_only=True,\r\n",
        "                                              )\r\n",
        "    \"\"\"\r\n",
        "    model.compile(loss='categorical_crossentropy',\r\n",
        "                  optimizer=K.optimizers.RMSprop(lr=2e-5),\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    history = model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=1,\r\n",
        "                        validation_data=(x_test, y_test),\r\n",
        "                        callbacks=[check_point])\r\n",
        "\r\n",
        "                        \"\"\"\r\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "0 input_1 - False\n",
            "1 conv1_pad - False\n",
            "2 conv1_conv - False\n",
            "3 conv1_bn - False\n",
            "4 conv1_relu - False\n",
            "5 pool1_pad - False\n",
            "6 pool1_pool - False\n",
            "7 conv2_block1_1_conv - False\n",
            "8 conv2_block1_1_bn - False\n",
            "9 conv2_block1_1_relu - False\n",
            "10 conv2_block1_2_conv - False\n",
            "11 conv2_block1_2_bn - False\n",
            "12 conv2_block1_2_relu - False\n",
            "13 conv2_block1_0_conv - False\n",
            "14 conv2_block1_3_conv - False\n",
            "15 conv2_block1_0_bn - False\n",
            "16 conv2_block1_3_bn - False\n",
            "17 conv2_block1_add - False\n",
            "18 conv2_block1_out - False\n",
            "19 conv2_block2_1_conv - False\n",
            "20 conv2_block2_1_bn - False\n",
            "21 conv2_block2_1_relu - False\n",
            "22 conv2_block2_2_conv - False\n",
            "23 conv2_block2_2_bn - False\n",
            "24 conv2_block2_2_relu - False\n",
            "25 conv2_block2_3_conv - False\n",
            "26 conv2_block2_3_bn - False\n",
            "27 conv2_block2_add - False\n",
            "28 conv2_block2_out - False\n",
            "29 conv2_block3_1_conv - False\n",
            "30 conv2_block3_1_bn - False\n",
            "31 conv2_block3_1_relu - False\n",
            "32 conv2_block3_2_conv - False\n",
            "33 conv2_block3_2_bn - False\n",
            "34 conv2_block3_2_relu - False\n",
            "35 conv2_block3_3_conv - False\n",
            "36 conv2_block3_3_bn - False\n",
            "37 conv2_block3_add - False\n",
            "38 conv2_block3_out - False\n",
            "39 conv3_block1_1_conv - False\n",
            "40 conv3_block1_1_bn - False\n",
            "41 conv3_block1_1_relu - False\n",
            "42 conv3_block1_2_conv - False\n",
            "43 conv3_block1_2_bn - False\n",
            "44 conv3_block1_2_relu - False\n",
            "45 conv3_block1_0_conv - False\n",
            "46 conv3_block1_3_conv - False\n",
            "47 conv3_block1_0_bn - False\n",
            "48 conv3_block1_3_bn - False\n",
            "49 conv3_block1_add - False\n",
            "50 conv3_block1_out - False\n",
            "51 conv3_block2_1_conv - False\n",
            "52 conv3_block2_1_bn - False\n",
            "53 conv3_block2_1_relu - False\n",
            "54 conv3_block2_2_conv - False\n",
            "55 conv3_block2_2_bn - False\n",
            "56 conv3_block2_2_relu - False\n",
            "57 conv3_block2_3_conv - False\n",
            "58 conv3_block2_3_bn - False\n",
            "59 conv3_block2_add - False\n",
            "60 conv3_block2_out - False\n",
            "61 conv3_block3_1_conv - False\n",
            "62 conv3_block3_1_bn - False\n",
            "63 conv3_block3_1_relu - False\n",
            "64 conv3_block3_2_conv - False\n",
            "65 conv3_block3_2_bn - False\n",
            "66 conv3_block3_2_relu - False\n",
            "67 conv3_block3_3_conv - False\n",
            "68 conv3_block3_3_bn - False\n",
            "69 conv3_block3_add - False\n",
            "70 conv3_block3_out - False\n",
            "71 conv3_block4_1_conv - False\n",
            "72 conv3_block4_1_bn - False\n",
            "73 conv3_block4_1_relu - False\n",
            "74 conv3_block4_2_conv - False\n",
            "75 conv3_block4_2_bn - False\n",
            "76 conv3_block4_2_relu - False\n",
            "77 conv3_block4_3_conv - False\n",
            "78 conv3_block4_3_bn - False\n",
            "79 conv3_block4_add - False\n",
            "80 conv3_block4_out - False\n",
            "81 conv4_block1_1_conv - False\n",
            "82 conv4_block1_1_bn - False\n",
            "83 conv4_block1_1_relu - False\n",
            "84 conv4_block1_2_conv - False\n",
            "85 conv4_block1_2_bn - False\n",
            "86 conv4_block1_2_relu - False\n",
            "87 conv4_block1_0_conv - False\n",
            "88 conv4_block1_3_conv - False\n",
            "89 conv4_block1_0_bn - False\n",
            "90 conv4_block1_3_bn - False\n",
            "91 conv4_block1_add - False\n",
            "92 conv4_block1_out - False\n",
            "93 conv4_block2_1_conv - False\n",
            "94 conv4_block2_1_bn - False\n",
            "95 conv4_block2_1_relu - False\n",
            "96 conv4_block2_2_conv - False\n",
            "97 conv4_block2_2_bn - False\n",
            "98 conv4_block2_2_relu - False\n",
            "99 conv4_block2_3_conv - False\n",
            "100 conv4_block2_3_bn - False\n",
            "101 conv4_block2_add - False\n",
            "102 conv4_block2_out - False\n",
            "103 conv4_block3_1_conv - False\n",
            "104 conv4_block3_1_bn - False\n",
            "105 conv4_block3_1_relu - False\n",
            "106 conv4_block3_2_conv - False\n",
            "107 conv4_block3_2_bn - False\n",
            "108 conv4_block3_2_relu - False\n",
            "109 conv4_block3_3_conv - False\n",
            "110 conv4_block3_3_bn - False\n",
            "111 conv4_block3_add - False\n",
            "112 conv4_block3_out - False\n",
            "113 conv4_block4_1_conv - False\n",
            "114 conv4_block4_1_bn - False\n",
            "115 conv4_block4_1_relu - False\n",
            "116 conv4_block4_2_conv - False\n",
            "117 conv4_block4_2_bn - False\n",
            "118 conv4_block4_2_relu - False\n",
            "119 conv4_block4_3_conv - False\n",
            "120 conv4_block4_3_bn - False\n",
            "121 conv4_block4_add - False\n",
            "122 conv4_block4_out - False\n",
            "123 conv4_block5_1_conv - False\n",
            "124 conv4_block5_1_bn - False\n",
            "125 conv4_block5_1_relu - False\n",
            "126 conv4_block5_2_conv - False\n",
            "127 conv4_block5_2_bn - False\n",
            "128 conv4_block5_2_relu - False\n",
            "129 conv4_block5_3_conv - False\n",
            "130 conv4_block5_3_bn - False\n",
            "131 conv4_block5_add - False\n",
            "132 conv4_block5_out - False\n",
            "133 conv4_block6_1_conv - False\n",
            "134 conv4_block6_1_bn - False\n",
            "135 conv4_block6_1_relu - False\n",
            "136 conv4_block6_2_conv - False\n",
            "137 conv4_block6_2_bn - False\n",
            "138 conv4_block6_2_relu - False\n",
            "139 conv4_block6_3_conv - False\n",
            "140 conv4_block6_3_bn - False\n",
            "141 conv4_block6_add - False\n",
            "142 conv4_block6_out - False\n",
            "143 conv5_block1_1_conv - True\n",
            "144 conv5_block1_1_bn - True\n",
            "145 conv5_block1_1_relu - True\n",
            "146 conv5_block1_2_conv - True\n",
            "147 conv5_block1_2_bn - True\n",
            "148 conv5_block1_2_relu - True\n",
            "149 conv5_block1_0_conv - True\n",
            "150 conv5_block1_3_conv - True\n",
            "151 conv5_block1_0_bn - True\n",
            "152 conv5_block1_3_bn - True\n",
            "153 conv5_block1_add - True\n",
            "154 conv5_block1_out - True\n",
            "155 conv5_block2_1_conv - True\n",
            "156 conv5_block2_1_bn - True\n",
            "157 conv5_block2_1_relu - True\n",
            "158 conv5_block2_2_conv - True\n",
            "159 conv5_block2_2_bn - True\n",
            "160 conv5_block2_2_relu - True\n",
            "161 conv5_block2_3_conv - True\n",
            "162 conv5_block2_3_bn - True\n",
            "163 conv5_block2_add - True\n",
            "164 conv5_block2_out - True\n",
            "165 conv5_block3_1_conv - True\n",
            "166 conv5_block3_1_bn - True\n",
            "167 conv5_block3_1_relu - True\n",
            "168 conv5_block3_2_conv - True\n",
            "169 conv5_block3_2_bn - True\n",
            "170 conv5_block3_2_relu - True\n",
            "171 conv5_block3_3_conv - True\n",
            "172 conv5_block3_3_bn - True\n",
            "173 conv5_block3_add - True\n",
            "174 conv5_block3_out - True\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1331)              2727219   \n",
            "=================================================================\n",
            "Total params: 30,519,475\n",
            "Trainable params: 21,903,667\n",
            "Non-trainable params: 8,615,808\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0BqXKCAfOCh"
      },
      "source": [
        "import cv2\r\n",
        "\r\n",
        "image = cv2.imread('photo-1503023345310-bd7c1de61c7d.jpg')\r\n",
        "dim = (32, 32)\r\n",
        "  \r\n",
        "# resize image\r\n",
        "resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4CS2_XOgecm"
      },
      "source": [
        "import numpy as np\r\n",
        "test = np.reshape(resized, (1,32,32,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ1MRO0NdofU",
        "outputId": "f9d7df56-7f65-4fe5-e3f6-207809019c11"
      },
      "source": [
        "model.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msfp2A-ngCiq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}